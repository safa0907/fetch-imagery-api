# -*- coding: utf-8 -*-

"""
/***************************************************************************
 Fetch
                                 A QGIS plugin
 Fetch Azure imagery based on a bounding box.
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2022-08-23
        copyright            : (C) 2022 by Sridene
        email                : sridene@blackshark.ai
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

__author__ = 'Sridene'
__date__ = '2022-08-23'
__copyright__ = '(C) 2022 by Sridene'

# This will get replaced with a git SHA1 when you do a git archive

__revision__ = '$Format:%H$'

import sys
import os
from qgis.PyQt.QtCore import QCoreApplication
import processing
from qgis.core import (QgsProcessing,
                       QgsFeatureSink,
                       QgsProcessingAlgorithm,
                       QgsProcessingParameterFeatureSource,
                       QgsProcessingParameterFeatureSink,
                       QgsProcessingParameterString,
                       QgsProcessingParameterBoolean,
                       QgsProcessingParameterExtent,
                       QgsProcessingParameterRasterDestination,
                       QgsProcessingParameterFileDestination,
                       QgsProcessingParameterEnum,
                       QgsProcessingParameterCrs,
                       QgsProcessingParameterExpression,
                       QgsExpression
                       )
import requests
import json
import pandas as pd


class FetchAlgorithm(QgsProcessingAlgorithm):
    """
    This is an example algorithm that takes a vector layer and
    creates a new identical one.

    It is meant to be used as an example of how to create your own
    algorithms and explain methods and variables used to do it. An
    algorithm like this will be available in all elements, and there
    is not need for additional work.

    All Processing algorithms should extend the QgsProcessingAlgorithm
    class.
    """

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    BANDS = 'BANDS'
    DATASET_ID = 'DATASET_ID'
    DATASET_NAME = 'DATASET_NAME'
    MASK_NODATA = 'MASK_NODATA'
    OUTPUT = 'OUTPUT'
    EXTENT = 'EXTENT'

    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """

        # We add the input vector features source. It can have any kind of
        # geometry.

        self.nimue_base_url: str = "https://nimue.gus.az.bshrk.net"
        self.nimue_api_version: str = "v5"
        self.query_endpoint_url: str = f"{self.nimue_base_url}/{self.nimue_api_version}/query/"
        self.datasets_endpoint_url: str = f"{self.nimue_base_url}/{self.nimue_api_version}/datasets/"
        self.dataset_id: int = 46
        self.ds_table_limit: int = 100
        self.d_parameters: dict = {}  # for easier handling of parameters names
        self._is_d_params_set: bool = False  # for easier handling of parameters names
        self.request_session: requests.sessions.Session = requests.sessions.Session()
        self.df_datasets: pd.DataFrame = None

        self._df_datasets_setter()
        self.dataset = self.df_datasets['id'].to_list()
        self.dataset_id = [str(x) for x in self.dataset]

        self.addParameter(QgsProcessingParameterString(self.BANDS, self.tr('Bands'), multiLine=False,
                                                       defaultValue='red,green,blue'))

        self.addParameter(
            QgsProcessingParameterEnum(self.DATASET_ID, self.tr('Dataset ID'), self.dataset_id, defaultValue=0))

        self.addParameter(QgsProcessingParameterString(self.DATASET_NAME, self.tr('Dataset Name')))
        # self.addParameter(QgsProcessingParameterBoolean(self.MASK_NODATA, self.tr('Mask Nodata'), defaultValue=False))

        self.addParameter(QgsProcessingParameterExtent(self.EXTENT, self.tr('Extent')))

        self.addParameter(QgsProcessingParameterRasterDestination(self.OUTPUT, self.tr('Output Raster')))

    def preprocess(self, parameters, context, feedback):
        dataset_ids = self.dataset_id[self.parameterAsEnum(parameters, self.DATASET_ID, context)]
        dataset_name = self.parameterAsString(parameters, self.DATASET_NAME, context)
        # Set project variable
        alg_params = {
            'NAME': 'name',
            'VALUE': QgsExpression(dataset_ids).evaluate()
        }
        outputs = {}
        dataset_name = processing.run('native:setprojectvariable', alg_params, context=context,
                                      feedback=feedback, is_child_algorithm=True)
        return dataset_ids, dataset_name

    def processAlgorithm(self, parameters, context, feedback):
        """
        Here is where the processing itself takes place.
        """
        bbox = self.parameterAsExtent(parameters, self.EXTENT, context)
        box = [
            str(bbox.xMinimum()),
            str(bbox.yMinimum()),
            str(bbox.xMaximum()),
            str(bbox.yMaximum()),
        ]
        bands = self.parameterAsString(parameters, self.BANDS, context)
        # dataset_ids = self.dataset_id[self.parameterAsEnum(parameters, self.DATASET_ID, context)]
        # datasetid = self.parameterAsString(parameters, self.DATASET_ID, context)

        '''dataset_name = self.parameterAsString(parameters, self.DATASET_NAME, context)
        # Set project variable
        alg_params = {
            'NAME': 'name',
            'VALUE': QgsExpression(dataset_ids).evaluate()
        }
        outputs = {}'''
        # outputs['SetProjectVariable'] = processing.run('native:setprojectvariable', alg_params, context=context,
        #                                              feedback=feedback, is_child_algorithm=True)
        # name = str(self.df_datasets.loc[self.df_datasets['id'] == int(self.dataset_ids), 'name'].values[0])
        # mask_nodata = self.parameterAsBool(parameters, self.MASK_NODATA, context)
        bboxCrs = 4326
        output = self.parameterAsOutputLayer(parameters, self.OUTPUT, context)
        compression = "geotiff_zstd"

        dataset_ids = self.preprocess(parameters,context,feedback)[0]
        dataset_name = self.preprocess(parameters, context, feedback)[1]
        response = self.fetch_raster(id=dataset_ids, bbox=box, crs_epsg=bboxCrs, bands=str(bands).split(','),
                                     endpoint_url=self.query_endpoint_url, output=output, session=self.request_session,
                                     compression_format=compression)

        return {self.OUTPUT: response, self.DATASET_NAME: dataset_name}

    def fetch_raster(self, id=46,
                     bbox=(-79.7370776029000012, 41.4025026221916406, -79.7270776029000012, 41.4035026221916406),
                     crs_epsg=4326,
                     bands=['red', 'green', 'blue'],
                     endpoint_url="https://nimue.gus.az.bshrk.net/v5/query/",
                     output=r"C:\Users\sridene\Downloads\out6.tif",
                     session=requests.sessions.Session(),
                     compression_format="geotiff_zstd"):
        """
        Fetches raster based on id
        :param id: id of the dataset
        :param bbox: bbox of the dataset(xmin,ymin,xmax,ymax)
        :param crs_epsg: desired epsg
        :param bands: desired bands
        :param endpoint_url: endpoint for the query
        :param output: output path file
        :param session: session used
        :return:
        """
        query_body = {'filters': [{'filter': 'by_dataset_id', 'id': id}],
                      'crop': {
                          'bounding_box': bbox,
                          'crs_epsg': crs_epsg},
                      'transfer_format': compression_format,
                      'merge_strategy': 'newest',
                      'bands': bands,
                      'pad_to_crop': False}
        try:
            with session as session_request:
                with session_request.post(endpoint_url, json=query_body) as query_resp:
                    if query_resp.status_code == 204:
                        return 204
                    query_resp.raise_for_status()
                    with open(output, "wb") as file:
                        file.write(query_resp.content)
                    return 200
        except Exception as err:
            raise Exception(f"Something went wrong: {err}")

    def _get_datasets(self, request_session: requests.sessions.Session, endpoint: str, limit: int = 100) -> list:
        """
        Get datasets with limit
        :param request_session:  session
        :param endpoint: endpoint for datasets
        :param limit: limit of fetched datasets
        :return: Code or content
        """
        query_body_params: dict = {
            "limit": limit,
            "offset": 0
        }
        try:
            with request_session.get(endpoint, params=query_body_params, timeout=300) as query_resp:
                if query_resp.status_code == 204:
                    return 204
                query_resp.raise_for_status()
                return json.loads(query_resp.content)
        except Exception as err:
            raise Exception(f"Something went wrong: {err}")

    def _df_datasets_setter(self):
        """
        A setter for datasets instance
        :return:
        """
        if not self.df_datasets:
            self.df_datasets = pd.json_normalize(
                self._get_datasets(self.request_session, self.datasets_endpoint_url, limit=100))

    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Fetch Azure Imagery'

    def shortHelpString(self):
        """
        Returns a localised short helper string for the algorithm. This string
        should provide a basic description about what the algorithm does and the
        parameters and outputs associated with it..
        """
        return self.tr("Fetch imagery from azure using nimue API.")

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return FetchAlgorithm()
